{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n(4) This script executes the SBERT model chatbot from the pickle file:\\n\\n1. Loads a pre-trained model and embeddings from a pickle file.\\n2. Preprocesses user queries by tokenizing, stemming, lemmatizing, and lowercasing the text.\\n3. Computes embeddings for user queries.\\n4. Finds the most relevant FAQ answer using cosine similarity.\\n5. Provides a command-line interface for user interaction.\\nThe chatbot responds to user queries based on precomputed FAQ data and embeddings. If no suitable answer is found, it provides a default message.\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "(4) This script executes the SBERT model chatbot from the pickle file:\n",
        "\n",
        "1. Loads a pre-trained model and embeddings from a pickle file.\n",
        "2. Preprocesses user queries by tokenizing, stemming, lemmatizing, and lowercasing the text.\n",
        "3. Computes embeddings for user queries.\n",
        "4. Finds the most relevant FAQ answer using cosine similarity.\n",
        "5. Provides a command-line interface for user interaction.\n",
        "The chatbot responds to user queries based on precomputed FAQ data and embeddings. If no suitable answer is found, it provides a default message.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JcE22bUTt3IS"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwHcvDthuLUq",
        "outputId": "829977c3-53b7-435e-8fe1-77441c2ae5f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/jjpark987/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/jjpark987/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/jjpark987/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Load NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jjpark987/Desktop/Entity-Extraction-Chatbot/venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "# Load model and embeddings from pickle file\n",
        "with open('model/keelworks_model.pkl', 'rb') as f:\n",
        "    model_data = pickle.load(f)\n",
        "\n",
        "model = model_data['model']\n",
        "faqs = model_data['faqs']\n",
        "faq_questions = model_data['faq_questions']\n",
        "faq_embeddings = model_data['faq_embeddings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kZNB5ZqLuUgJ"
      },
      "outputs": [],
      "source": [
        "# Preprocess text (tokenization, stemming, lemmatization, and lowercasing)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove non-alphanumeric characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    tokens = word_tokenize(text)  # Tokenize text\n",
        "    tokens = [stemmer.stem(word) for word in tokens]  # Apply stemming\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
        "    return ' '.join(tokens)  # Join tokens back into a single string\n",
        "\n",
        "# Generate SBERT embeddings\n",
        "def get_sbert_embedding(text):\n",
        "    embedding = model.encode(text)\n",
        "    return embedding\n",
        "\n",
        "# Find the best matching answer\n",
        "def get_best_answer(user_query, faqs, faq_embeddings, threshold=0.5):\n",
        "    preprocessed_query = preprocess_text(user_query)\n",
        "    query_embedding = get_sbert_embedding(preprocessed_query).reshape(1, -1)\n",
        "\n",
        "    similarities = cosine_similarity(query_embedding, faq_embeddings)\n",
        "    best_match_index = similarities.argmax()\n",
        "    best_match_score = similarities[0, best_match_index]\n",
        "\n",
        "    if best_match_score < threshold:\n",
        "        return \"Sorry, I don't have the answer. Please email to test@keelworks to get more info.\"\n",
        "    \n",
        "    return faqs[best_match_index]['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUzDKDvgvkmL",
        "outputId": "85b49d16-9ea4-4667-e7f5-63da6de80aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the KeelWorks Chatbot!\n",
            "Hello Jaosn, welcome to the KeelWorks bot. Ask me anything about KeelWorks.\n",
            "Bot: KeelWorks is a non-profit, charitable foundation established 13 years ago, focusing on empowering individuals globally, including in places like China, India, Egypt, Nigeria, Ghana, UK, Brazil, Kenya, Canada, and the USA. We help economically disadvantaged individuals gain new competencies, supporting their families and contributing to their communities.\n",
            "Bot: Sorry, I don't have the answer. Please email to test@keelworks to get more info.\n",
            "Goodbye, Jaosn!\n"
          ]
        }
      ],
      "source": [
        "# Command-Line Interface\n",
        "def chatbot():\n",
        "    print(\"Welcome to the KeelWorks Chatbot!\")\n",
        "    user_name = input(\"Please enter your name: \")\n",
        "    print(f\"Hello {user_name}, welcome to the KeelWorks bot. Ask me anything about KeelWorks.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nYou: \")\n",
        "        if user_query.lower() in ['exit', 'quit', 'bye']:\n",
        "            print(f\"Goodbye, {user_name}!\")\n",
        "            break\n",
        "        answer = get_best_answer(user_query, faqs, faq_embeddings)\n",
        "        print(f\"Bot: {answer}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
