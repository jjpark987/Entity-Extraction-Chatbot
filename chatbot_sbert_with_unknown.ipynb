{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6w-Di2Mwtah0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsbJRVMntd_A",
        "outputId": "b4b0485b-d16d-475c-e303-962a359d8bbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Load NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MeIjs5HZtiXZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Load the FAQs from the JSON file\n",
        "with open('data/keelworks_info.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "faqs = data['questions_and_answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DRwEab_ltecS"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained SBERT model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Preprocess text (tokenization, stemming, lemmatization, and lowercasing)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove non-alphanumeric characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    tokens = word_tokenize(text)  # Tokenize text\n",
        "    tokens = [stemmer.stem(word) for word in tokens]  # Apply stemming\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
        "    return ' '.join(tokens)  # Join tokens back into a single string\n",
        "\n",
        "# Generate SBERT embeddings\n",
        "def get_sbert_embedding(text):\n",
        "    embedding = model.encode(text)\n",
        "    return embedding\n",
        "\n",
        "# Precompute embeddings for FAQ questions\n",
        "faq_questions = [preprocess_text(faq['question']) for faq in faqs]\n",
        "faq_embeddings = np.array([get_sbert_embedding(question) for question in faq_questions])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2RMGfUAtmkq",
        "outputId": "d106efd1-4852-43a4-f6a5-7738acdc6fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and embeddings saved to keelworks_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# Save model and embeddings to a pickle file\n",
        "model_data = {\n",
        "    'model': model,\n",
        "    'faq_questions': faq_questions,\n",
        "    'faq_embeddings': faq_embeddings,\n",
        "    'faqs': faqs\n",
        "}\n",
        "\n",
        "with open('keelworks_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_data, f)\n",
        "\n",
        "print(\"Model and embeddings saved to keelworks_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
